<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <title>Can Qin</title>
  <meta content="Can Qin, github.com/canqin001" name="keywords" />
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 14pt;
}
b.paper {
  font-weight: bold;
  font-size: 14pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1000px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 18px;
  font-weight: 700;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
  font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'kailigo.github.io');
  ga('send', 'pageview');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Can Qin" style="float: left; padding-left: .5em; height: 140px;" src="qincan_LD.jpg" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Can Qin (秦灿)</span><br />
<span><strong>Ph.D Student</strong></span><br />
<!--<span><a href='http://cvrs.whu.edu.cn/'>Computer Vision & Remote Sensing (CVRS) Lab </a> <br /> </q>-->
<span>Electrical and Computer Engineering Department, Northeastern University, Boston, MA, USA.</span><br />
<span><strong>Office</strong>: Richard Hall, 360 Huntington Ave, Boston, MA 02115</span><br />
<span><strong>Email </strong>: qin.ca [at] husky.neu.edu  &nbsp &nbsp  
<strong><a href=' '>CV</a></strong>  &nbsp &nbsp
<strong><a href='https://github.com/canqin001'>Github</a></strong>  &nbsp &nbsp
<strong><a href='https://scholar.google.com/citations?user=QCik-YcAAAAJ&hl=en&authuser=1'>Google Scholar</a></strong></span><br/>
<!-- <span><strong> <a href='https://github.com/kailigo'>Github</a> </strong></span> <br /> -->
<!-- <span><strong> <a href='https://scholar.google.com/citations?hl=en&user=YsROc4UAAAAJ'>Google Scholar</a> </strong></span> <br /> -->
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>About Me</h2>
<div class="paper">
I’m a second-year Ph.D student in the <a href='http://www.ece.neu.edu/'>Department of Electrical & Computer Engineering</a>, <a href='http://www.northeastern.edu/'>Northeastern University (NEU)</a> under the supervision of <a href='http://www1.ece.neu.edu/~yunfu/'>Prof. Yun Raymond Fu</a>. I received my B.E. degree from the School of Microelectronics, Xidian University (XDU), China, in 2018. My research interest lies in machine learning and computer vision.
<!--I am a fourth-year PhD student in the <a href='http://www.ece.neu.edu/'>Electrical and Computer Engineering Department</a>, <a href='http://www.northeastern.edu/'>Northeastern University</a>, advised by <a href='http://www1.ece.neu.edu/~yunfu/'> Prof. Yun Fu</a>. My current research interests lie in computer vision and deep learning. I have spent time at  <a href='https://research.adobe.com/'>Adobe Research</a>, <a href='https://ailab.bytedance.com/'>Bytedance AI Lab U.S.</a> and <a href='https://new.siemens.com/global/en/company/innovation/corporate-technology.html'>Siemens Research</a> as a research intern.-->



<!-- Prior to this, I obtained my bachelor degree from School of Electronic and Information Engineering, <a href='https://www.scut.edu.cn/new/'>South China University of Technology</a>, supervised by Prof. Xin Zhang and <a href='http://www.hcii-lab.net/lianwen/'>Prof. Lianwen Jin</a>. -->


</div>
</div>
</div>

<div style="clear: both;">
  <div class="section">
    <h2>Research Interests</h2>
    <div class="paper">
      <ul>
    <li> Transfer Learning and Domain Adaptation.</li>
    <li> Self-supervised/Semi-supervised/Few-shot/Zero-shot Learning.</li>
    <li> Deep Learning for Image Classification, Segmentation and 3D Vision.</li>
    </div>
  </div>
  </div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
<!--   <li> 2018.07: One paper is accepted by <strong> ECCV 2018 </strong>.</li> 
  <li> 2018.07: One paper is accepted by <strong> ACM MM 2018 </strong> .</li>  -->
  <li> 2019.11: Our paper is accepted by <strong> AAAI 2020 </strong> as <strong> Poster </strong>.</li>
  <li> 2019.10: Our paper is awarded as <strong> <a href='  '>the Best Paper</a> </strong> of <strong><a href='https://www.forlq.org'>ICCVW on RLQ, 2019</a> </strong>.</li>
  <li> 2019.09: Our paper is accepted by <strong> NeurIPS 2019 </strong> as <strong> Poster </strong>.</li>
  <li> 2019.08: Our paper is accepted by <strong> ICCVW on RLQ, 2019 </strong> as <strong> Oral </strong>.</li>
  <li> 2019.06: Start my internship at <strong> Adobe </strong> in San Jose.</li>  
  <li> 2018.09: Begin my journey in <strong> Smile Lab, Northeastern University </strong> at Boston.</li>   
    </ul>
  </div>
</div>
</div>




<!-- <div style="clear: both;">
<div class="section">
<h2 id="confpapers">Intern Experience</h2>


 -->


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications</h2>


 <div class="paper" id="AAAI20"><img class="paper" src="./pic/AAAI20.png" title="Dual Relation Semi-supervised Multi-label Learning">
<div> <strong>Dual Relation Semi-supervised Multi-label Learning</strong><br>
  Lichen Wang, Yunyu Liu, <strong><u>Can Qin</u></strong>, Gan Sun, Yun Fu <br>
  Thirty-Fourth AAAI Conference on Artificial Intelligence (<strong><u>AAAI</u></strong>), 2020.<br>
<a>[PDF]</a>
<a>[code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="PointDAN"><img class="paper" src="./pic/PointDAN.png" title="PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation">
<div> <strong>PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation</strong><br>
  <strong><u>Can Qin*</u></strong>, Haoxuan You*, Lichen Wang, C.-C. Jay Kuo, Yun Fu. (* equal contribution) <br>
  Advances in Neural Information Processing Systems (<strong><u>NeurIPS</u></strong>), 2019.<br>
<a href='http://papers.nips.cc/paper/8940-pointdan-a-multi-scale-3d-domain-adaption-network-for-point-cloud-representation.pdf'>[PDF]</a>
<a href='https://github.com/canqin001/PointDAN'>[code]</a>
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="GICT"><img class="paper" src="./pic/GICT.png" title="Generatively Inferential Co-Training for Unsupervised Domain Adaptation">
<div> <strong>Generatively Inferential Co-Training for Unsupervised Domain Adaptation</strong><br>
<strong><u>Can Qin</u></strong>, Lichen Wang, Yulun Zhang, Yun Fu.<br>
ICCV Workshop on Real-World Recognition from Low-Quality Images and Videos, 2019. (<strong><u><a href='  '>Best Paper Award</a> </u></strong>)<br>
<a href='http://openaccess.thecvf.com/content_ICCVW_2019/papers/RLQ/Qin_Generatively_Inferential_Co-Training_for_Unsupervised_Domain_Adaptation_ICCVW_2019_paper.pdf'>[PDF]</a>
<a href='https://github.com/ChinTsan01/Generatively-Inferential-Co-Training-for-UDA'>[code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="AAAIW18"><img class="paper" src="./pic/AAAIW18.png" title="Efficient Scene Labeling via Sparse Annotations">
<div> <strong>Efficient Scene Labeling via Sparse Annotations</strong><br>
  <strong><u>Can Qin</u></strong>, Maoguo Gong, Yue Wu, Dayong Tian, Puzhao Zhang.<br>
Smart IoT Workshop at the AAAI Conference on Artificial Intelligence, 2018.<br>
<a href='https://www.aaai.org/ocs/index.php/WS/AAAIW18/paper/viewFile/17020/15569'>[PDF]</a>
<a>[code]</a>
</div>
<div class="spanner"></div>
</div>


 <div class="paper" id="MFLR"><img class="paper" src="./pic/MFLR.png" title="A Multi-objective Framework for Location Recommendation Based on User Preference"> 
  <div> <strong>A Multi-objective Framework for Location Recommendation Based on User Preference</strong><br>
    Shanfeng Wang, Maoguo Gong, <strong><u>Can Qin</u></strong>, Junwei Yang<br>
    IEEE Conference on Computational Intelligence and Security (<strong>CIS</strong>), 2017<br>
  <a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288439'>[PDF]</a>
  <a>[code]</a>
  </div>
  <div class="spanner"></div>
  </div>

 <div class="paper" id="LPMF"><img class="paper" src="./pic/LPMF.png" title="Local Probabilistic Matrix Factorization for Personal Recommendation"> 
<div> <strong>Local Probabilistic Matrix Factorization for Personal Recommendation</strong><br>
  Wenping Ma, Yue Wu, Maoguo Gong, <strong><u>Can Qin</u></strong>, Shanfeng Wang.<br>
  IEEE Conference on Computational Intelligence and Security (<strong>CIS</strong>), 2017<br>
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288451'>[PDF]</a>
<a>[code]</a>
</div>
<div class="spanner"></div>
</div>




<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Awards</h2>
<div class="paper">
    <ul>
        <li>Best Paper Award of ICCV Workshop on RLQ, 2019</li>
        <li>The Star of 2018-Graduates in XDU (Highest honor, top 1%) , 2018</li>
        <li>The First Prize Scholarship in XDU (Top 5%) , 2016, 2017</li>
        <li>Meritorious Winner of the Interdisciplinary Contest in Modeling, 2016 </li>
        <li> Outstanding Student Leader in XDU, 2015</li>  
    <!-- <li> Best Undergraduate Thesis, School of Remote Sensing and Information Engineering, Wuhan University, 2014. </li> -->
    <!-- <li> Excellent Undergraduate Students, Wuhan University, 2012. </li> -->
    </ul>
</ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professonal Activities</h2>
<div class="paper">
<ul>
<p><font size="5">
    <li>External Reviewer for IEEE Computational Intelligence Magazine.</li>
    <li>Volunteer for 13th IEEE Conference on Automatic Face and Gesture Recognition, 2018.</li>
  <!-- <li> Reviewer for CVPR 2019, 2020, ICCV 2019, AAAI 2019, 2020, TIP, TNNLS, TMI, TMM </li>   -->     
  <!-- <li> External Reviewer for CVPR, ICCV, ECCV, AAAI, IJCAI, AAAI (2017). </li> -->
    <!-- <li> Guest reviewer for AAAI 2017. </li>       -->
  <!-- <li> IEEE student member, AAAI student member. </li>    -->
</font></p>
</ul>
</div>
</div>
</div>


<div style="clear: both;">
  <div class="section">
  <h2 id="confpapers">Programming Skills</h2>
  <div class="paper">
  <ul>
  <p><font size="5">
      <li>Language: Python, MATLAB, C, LATEX and others.</li>
      <li>Machine Learning Frameworks: PyTorch, TensorFlow, Keras, Sklearn, OpenCV and others.</li>
    <!-- <li> Reviewer for CVPR 2019, 2020, ICCV 2019, AAAI 2019, 2020, TIP, TNNLS, TMI, TMM </li>   -->     
    <!-- <li> External Reviewer for CVPR, ICCV, ECCV, AAAI, IJCAI, AAAI (2017). </li> -->
      <!-- <li> Guest reviewer for AAAI 2017. </li>       -->
    <!-- <li> IEEE student member, AAAI student member. </li>    -->
  </font></p>
  </ul>
  </div>
  </div>
  </div>

  
<!-- <div style="clear:both;">
<p align="right"><font size="5">Last Updated on 11th Dec, 2017</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div> -->

<!-- <hr> -->
<!--  -->
<!-- <div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=IF-jAGUNTygi5pa59hxIgtJU2XqT-rGoO58Z3E1vHZk&cl=ffffff&w=a"></script> -->
<div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=lKYNICJJ1cM7pDCFPKYtMa5bJS9414rBlFiHb7RKULc&cl=ffffff&w=a"></script>
<!-- -->
</body>
</html>
